{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Cleaning_Kaggle_Course.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPii6wg6tCaDuZOwxLkTqHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaquelMichelon/Data_Cleaning_Kaggle_Course/blob/main/Data_Cleaning_Kaggle_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning [Kaggle Course](https://www.kaggle.com/learn/data-cleaning)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FFeDynKkBOWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Handling Missing Values\n"
      ],
      "metadata": {
        "id": "OPIWNe4TXJbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Take a first look at the data"
      ],
      "metadata": {
        "id": "U0eb2_cuXWBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1C3DvgtXDob"
      },
      "outputs": [],
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in all our data\n",
        "nfl_data = pd.read_csv(\"../input/nflplaybyplay2009to2016/NFL Play by Play 2009-2017 (v4).csv\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the first five rows of the nfl_data file. \n",
        "# I can see a handful of missing data already!\n",
        "nfl_data.head()"
      ],
      "metadata": {
        "id": "oFmxUbdBX38T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How many missing data points do we have?"
      ],
      "metadata": {
        "id": "ebisLPT-YIPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of missing data points per column\n",
        "missing_values_count = nfl_data.isnull().sum()\n",
        "\n",
        "# look at the # of missing points in the first ten columns\n",
        "missing_values_count[0:10]"
      ],
      "metadata": {
        "id": "Yzi5WPpTYCSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see what percentage of the values in our dataset were missing and have a better sense of the scale of this problem"
      ],
      "metadata": {
        "id": "bEjkV439YppT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how many total missing values do we have?\n",
        "total_cells = np.product(nfl_data.shape)\n",
        "total_missing = missing_values_count.sum()\n",
        "\n",
        "# percent of data that is missing\n",
        "percent_missing = (total_missing/total_cells) * 100\n",
        "print(percent_missing)"
      ],
      "metadata": {
        "id": "oNnZkXV2Ylc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Figure out why the data is missing"
      ],
      "metadata": {
        "id": "KmP9Qux2ZA2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is this value missing because it wasn't recorded or because it doesn't exist?**\n",
        "\n",
        "If a value is missing because it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row. This is called **imputation**."
      ],
      "metadata": {
        "id": "d6KI-RiFZT7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the # of missing points in the first ten columns\n",
        "missing_values_count[0:10]"
      ],
      "metadata": {
        "id": "TKvNMR1dZCtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are fields, like \"PenalizedTeam\" that have lot of missing fields. In this case, though, the field is missing because if there was no penalty then it doesn't make sense to say which team was penalized. For this column, it would make more sense to either leave it empty or to add a third value like \"neither\" and use that to replace the NA's."
      ],
      "metadata": {
        "id": "Y81mlV18avI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking at the documentation, the column \"TimesSec\" has information on the number of seconds left in the game when the play was made. This means that these values are probably missing because they were not recorded, rather than because they don't exist. So, it would make sense for us to try and guess what they should be rather than just leaving them as NA's."
      ],
      "metadata": {
        "id": "4atKvu1Ia5KX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Drop missing values\n",
        "\n",
        "One option is to just remove any rows or columns that contain missing values"
      ],
      "metadata": {
        "id": "Zo8nnQjZcU-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all the rows that contain a missing value\n",
        "nfl_data.dropna()"
      ],
      "metadata": {
        "id": "5Nl2c-k-ccw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all columns with at least one missing value\n",
        "columns_with_na_dropped = nfl_data.dropna(axis=1)\n",
        "columns_with_na_dropped.head()"
      ],
      "metadata": {
        "id": "AH3noC6DSN6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just how much data did we lose?\n",
        "print(\"Columns in original dataset: %d \\n\" % nfl_data.shape[1])\n",
        "print(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])"
      ],
      "metadata": {
        "id": "igFxgsevSSZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Filling in missing values automatically"
      ],
      "metadata": {
        "id": "wo5lhUXKSYfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a small subset of the NFL dataset\n",
        "subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\n",
        "subset_nfl_data"
      ],
      "metadata": {
        "id": "ksqrHJOgSaP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the NaN values to be replaced with. Here, I'm saying that I would like to replace all the NaN values with 0."
      ],
      "metadata": {
        "id": "zWfGfEkBSuS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace all NA's with 0\n",
        "subset_nfl_data.fillna(0)"
      ],
      "metadata": {
        "id": "1BwPlIP7SvMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)"
      ],
      "metadata": {
        "id": "XICRcSIWS5WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace all NA's the value that comes directly after it in the same column, \n",
        "# then replace all the remaining na's with 0\n",
        "subset_nfl_data.fillna(method='bfill', axis=0).fillna(0)"
      ],
      "metadata": {
        "id": "2Q25z6d4S6i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Practice\n",
        "\n"
      ],
      "metadata": {
        "id": "n1693CSnTnOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read in all our data\n",
        "sf_permits = pd.read_csv(\"../input/building-permit-applications-data/Building_Permits.csv\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0) "
      ],
      "metadata": {
        "id": "zFWtSD1dTtLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sf_permits.head(5)"
      ],
      "metadata": {
        "id": "rAUILd3zUEkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first five rows of the data does show that several columns have missing values. You can see this in the \"Street Number Suffix\", \"Proposed Construction Type\" and \"Site Permit\" columns, among others."
      ],
      "metadata": {
        "id": "lYLAFjxHV1xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How many missing data points do we have?\n",
        "\n",
        "missing_values_count = sf_permits.isnull().sum()\n",
        "total_cells = np.product(sf_permits.shape)\n",
        "total_missing = missing_values_count.sum()\n",
        "percent_missing = (total_missing/total_cells) * 100\n",
        "print(percent_missing)"
      ],
      "metadata": {
        "id": "jqNUVKhPV3DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Figure out why the data is missing"
      ],
      "metadata": {
        "id": "p4HfgR0pXKCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a value in the \"Street Number Suffix\" column is missing, it is likely because it does not exist. If a value in the \"Zipcode\" column is missing, it was not recorded."
      ],
      "metadata": {
        "id": "stHInL_QXwgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop missing values: rows\n",
        "\n",
        "df_without_missing_values = sf_permits.dropna()\n",
        "df_without_missing_values.shape\n",
        "\n",
        "#oops, there are no rows remaining in the dataset"
      ],
      "metadata": {
        "id": "HHVbZyOmXzTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop missing values: columns\n",
        "\n",
        "sf_permits_with_na_dropped = sf_permits.dropna(axis=1)\n",
        "\n",
        "#to know how many columns were dropped\n",
        "dropped_columns = sf_permits.shape[1] - sf_permits_with_na_dropped.shape[1]"
      ],
      "metadata": {
        "id": "0XqUrExQi5G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill in missing values automatically\n",
        "\n",
        "sf_permits_with_na_imputed = sf_permits.fillna(method='bfill', axis=0).fillna(0)"
      ],
      "metadata": {
        "id": "i3k6rbXfj8mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More practice - Look back at the \"Zipcode\" column in the sf_permits dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset. You can search for datasets about San Fransisco on the Datasets listing.)\n",
        "\n",
        "[Learn More with Kaggle](https://www.kaggle.com/code/alexisbcook/missing-values/tutorial)"
      ],
      "metadata": {
        "id": "Spa_wlwplUcl"
      }
    }
  ]
}